{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_comment</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>family mormon never tried explain still stare ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>buddhism much lot compatible christianity espe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seriously say thing first get complex explain ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>learned want teach different focus goal not wr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>benefit may want read living buddha living chr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36788</th>\n",
       "      <td>jesus</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36789</th>\n",
       "      <td>kya bhai pure saal chutiya banaya modi aur jab...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36790</th>\n",
       "      <td>downvote karna tha par upvote hogaya</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36791</th>\n",
       "      <td>haha nice</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36792</th>\n",
       "      <td>facebook working bjp cell</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36793 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           clean_comment  category\n",
       "0      family mormon never tried explain still stare ...         1\n",
       "1      buddhism much lot compatible christianity espe...         1\n",
       "2      seriously say thing first get complex explain ...        -1\n",
       "3      learned want teach different focus goal not wr...         0\n",
       "4      benefit may want read living buddha living chr...         1\n",
       "...                                                  ...       ...\n",
       "36788                                              jesus         0\n",
       "36789  kya bhai pure saal chutiya banaya modi aur jab...         1\n",
       "36790               downvote karna tha par upvote hogaya         0\n",
       "36791                                          haha nice         1\n",
       "36792                          facebook working bjp cell         0\n",
       "\n",
       "[36793 rows x 2 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\anime\\OneDrive\\Desktop\\Data Science Projects\\Youtube Comment Analysis\\youtube_comment_analyser\\data\\processed\\reddit_preprocessing.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36661, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df =  df.dropna(subset=[\"clean_comment\"])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anime\\OneDrive\\Desktop\\Data Science Projects\\Youtube Comment Analysis\\comment_analysis\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import optuna\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='s3://datascienceanimesh/516785590309530379', creation_time=1743657286448, experiment_id='516785590309530379', last_update_time=1743657286448, lifecycle_stage='active', name='ML Algos with Revised HP Tuning', tags={}>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(os.getenv(\"MLFLOW_TRACKING_URI\"))\n",
    "mlflow.set_experiment(\"ML Algos with Revised HP Tuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-03 11:24:19,984] A new study created in memory with name: no-name-09252d46-fcb3-4472-96b9-b4d5b5859a0d\n",
      "[I 2025-04-03 11:24:23,140] Trial 0 finished with value: 0.6568658333568395 and parameters: {'n_estimators': 98, 'max_depth': 13, 'min_samples_split': 19, 'min_samples_leaf': 17}. Best is trial 0 with value: 0.6568658333568395.\n",
      "[I 2025-04-03 11:24:29,677] Trial 1 finished with value: 0.6648478894520273 and parameters: {'n_estimators': 171, 'max_depth': 16, 'min_samples_split': 8, 'min_samples_leaf': 15}. Best is trial 1 with value: 0.6648478894520273.\n",
      "[I 2025-04-03 11:24:43,624] Trial 2 finished with value: 0.6727795936647759 and parameters: {'n_estimators': 248, 'max_depth': 18, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 2 with value: 0.6727795936647759.\n",
      "[I 2025-04-03 11:24:48,804] Trial 3 finished with value: 0.6313027506167627 and parameters: {'n_estimators': 229, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 18}. Best is trial 2 with value: 0.6727795936647759.\n",
      "[I 2025-04-03 11:24:56,302] Trial 4 finished with value: 0.6617158874930902 and parameters: {'n_estimators': 202, 'max_depth': 14, 'min_samples_split': 11, 'min_samples_leaf': 19}. Best is trial 2 with value: 0.6727795936647759.\n",
      "[I 2025-04-03 11:25:01,400] Trial 5 finished with value: 0.6425182399534594 and parameters: {'n_estimators': 178, 'max_depth': 8, 'min_samples_split': 20, 'min_samples_leaf': 10}. Best is trial 2 with value: 0.6727795936647759.\n",
      "[I 2025-04-03 11:25:07,414] Trial 6 finished with value: 0.6282210494863916 and parameters: {'n_estimators': 250, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 2 with value: 0.6727795936647759.\n",
      "[I 2025-04-03 11:25:13,438] Trial 7 finished with value: 0.6650501138437555 and parameters: {'n_estimators': 134, 'max_depth': 15, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 2 with value: 0.6727795936647759.\n",
      "[I 2025-04-03 11:25:18,644] Trial 8 finished with value: 0.6299892620941201 and parameters: {'n_estimators': 244, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 2 with value: 0.6727795936647759.\n",
      "[I 2025-04-03 11:25:33,655] Trial 9 finished with value: 0.675659338436253 and parameters: {'n_estimators': 258, 'max_depth': 19, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 9 with value: 0.675659338436253.\n",
      "[I 2025-04-03 11:25:56,631] Trial 10 finished with value: 0.6794987428621899 and parameters: {'n_estimators': 295, 'max_depth': 19, 'min_samples_split': 15, 'min_samples_leaf': 1}. Best is trial 10 with value: 0.6794987428621899.\n",
      "[I 2025-04-03 11:26:22,039] Trial 11 finished with value: 0.6814692181520514 and parameters: {'n_estimators': 297, 'max_depth': 20, 'min_samples_split': 16, 'min_samples_leaf': 1}. Best is trial 11 with value: 0.6814692181520514.\n",
      "[I 2025-04-03 11:26:47,617] Trial 12 finished with value: 0.680964001786375 and parameters: {'n_estimators': 287, 'max_depth': 20, 'min_samples_split': 17, 'min_samples_leaf': 1}. Best is trial 11 with value: 0.6814692181520514.\n",
      "[I 2025-04-03 11:26:59,360] Trial 13 finished with value: 0.6544911773163558 and parameters: {'n_estimators': 293, 'max_depth': 10, 'min_samples_split': 16, 'min_samples_leaf': 1}. Best is trial 11 with value: 0.6814692181520514.\n",
      "[I 2025-04-03 11:27:19,078] Trial 14 finished with value: 0.6772760103848684 and parameters: {'n_estimators': 300, 'max_depth': 20, 'min_samples_split': 15, 'min_samples_leaf': 5}. Best is trial 11 with value: 0.6814692181520514.\n",
      "[I 2025-04-03 11:27:31,365] Trial 15 finished with value: 0.6695463008214185 and parameters: {'n_estimators': 275, 'max_depth': 17, 'min_samples_split': 17, 'min_samples_leaf': 13}. Best is trial 11 with value: 0.6814692181520514.\n",
      "[I 2025-04-03 11:27:41,127] Trial 16 finished with value: 0.6611601022660134 and parameters: {'n_estimators': 211, 'max_depth': 12, 'min_samples_split': 13, 'min_samples_leaf': 1}. Best is trial 11 with value: 0.6814692181520514.\n",
      "[I 2025-04-03 11:27:44,138] Trial 17 finished with value: 0.6703547644304092 and parameters: {'n_estimators': 52, 'max_depth': 20, 'min_samples_split': 18, 'min_samples_leaf': 7}. Best is trial 11 with value: 0.6814692181520514.\n",
      "[I 2025-04-03 11:27:48,360] Trial 18 finished with value: 0.6124082354492314 and parameters: {'n_estimators': 270, 'max_depth': 3, 'min_samples_split': 14, 'min_samples_leaf': 3}. Best is trial 11 with value: 0.6814692181520514.\n",
      "[I 2025-04-03 11:27:54,284] Trial 19 finished with value: 0.6498436028411991 and parameters: {'n_estimators': 148, 'max_depth': 10, 'min_samples_split': 13, 'min_samples_leaf': 5}. Best is trial 11 with value: 0.6814692181520514.\n",
      "[I 2025-04-03 11:28:04,908] Trial 20 finished with value: 0.6673234534728822 and parameters: {'n_estimators': 213, 'max_depth': 17, 'min_samples_split': 9, 'min_samples_leaf': 12}. Best is trial 11 with value: 0.6814692181520514.\n",
      "[I 2025-04-03 11:28:28,379] Trial 21 finished with value: 0.6805598337992212 and parameters: {'n_estimators': 285, 'max_depth': 20, 'min_samples_split': 17, 'min_samples_leaf': 1}. Best is trial 11 with value: 0.6814692181520514.\n",
      "[I 2025-04-03 11:28:48,073] Trial 22 finished with value: 0.6786905089956287 and parameters: {'n_estimators': 279, 'max_depth': 20, 'min_samples_split': 18, 'min_samples_leaf': 3}. Best is trial 11 with value: 0.6814692181520514.\n",
      "[I 2025-04-03 11:29:09,015] Trial 23 finished with value: 0.6768211969555044 and parameters: {'n_estimators': 274, 'max_depth': 18, 'min_samples_split': 20, 'min_samples_leaf': 1}. Best is trial 11 with value: 0.6814692181520514.\n",
      "[I 2025-04-03 11:29:23,393] Trial 24 finished with value: 0.6673235045267554 and parameters: {'n_estimators': 226, 'max_depth': 16, 'min_samples_split': 17, 'min_samples_leaf': 6}. Best is trial 11 with value: 0.6814692181520514.\n",
      "[I 2025-04-03 11:29:56,494] Trial 25 finished with value: 0.6741942582006241 and parameters: {'n_estimators': 298, 'max_depth': 18, 'min_samples_split': 12, 'min_samples_leaf': 3}. Best is trial 11 with value: 0.6814692181520514.\n",
      "[I 2025-04-03 11:30:13,786] Trial 26 finished with value: 0.665100772049434 and parameters: {'n_estimators': 239, 'max_depth': 15, 'min_samples_split': 7, 'min_samples_leaf': 9}. Best is trial 11 with value: 0.6814692181520514.\n",
      "[I 2025-04-03 11:30:52,096] Trial 27 finished with value: 0.6804587981841669 and parameters: {'n_estimators': 272, 'max_depth': 20, 'min_samples_split': 16, 'min_samples_leaf': 2}. Best is trial 11 with value: 0.6814692181520514.\n",
      "[I 2025-04-03 11:31:21,939] Trial 28 finished with value: 0.6717187707605788 and parameters: {'n_estimators': 257, 'max_depth': 17, 'min_samples_split': 18, 'min_samples_leaf': 5}. Best is trial 11 with value: 0.6814692181520514.\n",
      "[I 2025-04-03 11:31:30,748] Trial 29 finished with value: 0.6580276918760907 and parameters: {'n_estimators': 95, 'max_depth': 13, 'min_samples_split': 19, 'min_samples_leaf': 8}. Best is trial 11 with value: 0.6814692181520514.\n",
      "2025/04/03 11:32:13 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run RandomForest_UnderSampler_TFIDF_Bigrams at: http://ec2-16-171-237-43.eu-north-1.compute.amazonaws.com:5000/#/experiments/516785590309530379/runs/50e43e5274fb4fc3af898d9eaec94385\n",
      "🧪 View experiment at: http://ec2-16-171-237-43.eu-north-1.compute.amazonaws.com:5000/#/experiments/516785590309530379\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import optuna\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Step 1: Remove rows where 'category' is NaN\n",
    "df = df.dropna(subset=['category'])\n",
    "\n",
    "# Step 2: Train-test split BEFORE TF-IDF vectorization\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
    "    df['clean_comment'], df['category'], test_size=0.2, random_state=42, stratify=df['category']\n",
    ")\n",
    "\n",
    "# Step 3: TF-IDF vectorization applied only on training data\n",
    "ngram_range = (1, 2)  # Use bigram features\n",
    "max_features = 1000  # Limit vocabulary size\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=ngram_range, max_features=max_features)\n",
    "X_train = vectorizer.fit_transform(X_train_raw)  # Fit on training data\n",
    "X_test = vectorizer.transform(X_test_raw)  # Transform test data separately\n",
    "\n",
    "# Step 4: Apply RandomUnderSampler to balance classes in the training set\n",
    "undersampler = RandomUnderSampler(random_state=42)\n",
    "X_train_resampled, y_train_resampled = undersampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# Function to log results in MLflow\n",
    "def log_mlflow(model_name, model, X_train, X_test, y_train, y_test):\n",
    "    with mlflow.start_run():\n",
    "        # Log model type\n",
    "        mlflow.set_tag(\"mlflow.runName\", f\"{model_name}_UnderSampler_TFIDF_Bigrams\")\n",
    "        mlflow.set_tag(\"experiment_type\", \"algorithm_comparison\")\n",
    "\n",
    "        # Log algorithm name as a parameter\n",
    "        mlflow.log_param(\"algo_name\", model_name)\n",
    "\n",
    "        # Train model\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Log accuracy\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "        # Log classification report\n",
    "        classification_rep = classification_report(y_test, y_pred, output_dict=True)\n",
    "        for label, metrics in classification_rep.items():\n",
    "            if isinstance(metrics, dict):\n",
    "                for metric, value in metrics.items():\n",
    "                    mlflow.log_metric(f\"{label}_{metric}\", value)\n",
    "\n",
    "        # Log the model\n",
    "        mlflow.sklearn.log_model(model, f\"{model_name}_model\")\n",
    "\n",
    "\n",
    "# Step 6: Optuna objective function for Random Forest using cross-validation\n",
    "def objective_rf(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 300)  # Number of trees in the forest\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 20)  # Maximum depth of the tree\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)  # Minimum samples required to split a node\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 20)  # Minimum samples required at a leaf node\n",
    "\n",
    "    # RandomForestClassifier setup\n",
    "    model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth,\n",
    "                                   min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf,\n",
    "                                   random_state=42)\n",
    "\n",
    "    # Use cross-validation on resampled training data\n",
    "    cv_scores = cross_val_score(model, X_train_resampled, y_train_resampled, cv=5, scoring='accuracy')\n",
    "    return np.mean(cv_scores)  # Return mean accuracy of cross-validation\n",
    "\n",
    "\n",
    "# Step 7: Run Optuna for Random Forest, log the best model only\n",
    "def run_optuna_experiment():\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective_rf, n_trials=30)\n",
    "\n",
    "    # Get the best parameters and log only the best model\n",
    "    best_params = study.best_params\n",
    "    best_model = RandomForestClassifier(n_estimators=best_params['n_estimators'],\n",
    "                                        max_depth=best_params['max_depth'],\n",
    "                                        min_samples_split=best_params['min_samples_split'],\n",
    "                                        min_samples_leaf=best_params['min_samples_leaf'],\n",
    "                                        random_state=42)\n",
    "\n",
    "    # Train the best model on the resampled training set\n",
    "    best_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "    # Log the best model using MLflow\n",
    "    log_mlflow(\"RandomForest\", best_model, X_train_resampled, X_test, y_train_resampled, y_test)\n",
    "\n",
    "# Run the experiment for Random Forest\n",
    "run_optuna_experiment()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comment_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
