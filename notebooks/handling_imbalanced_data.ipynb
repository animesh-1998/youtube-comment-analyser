{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_comment</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>family mormon never tried explain still stare ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>buddhism much lot compatible christianity espe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seriously say thing first get complex explain ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>learned want teach different focus goal not wr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>benefit may want read living buddha living chr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36788</th>\n",
       "      <td>jesus</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36789</th>\n",
       "      <td>kya bhai pure saal chutiya banaya modi aur jab...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36790</th>\n",
       "      <td>downvote karna tha par upvote hogaya</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36791</th>\n",
       "      <td>haha nice</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36792</th>\n",
       "      <td>facebook working bjp cell</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36793 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           clean_comment  category\n",
       "0      family mormon never tried explain still stare ...         1\n",
       "1      buddhism much lot compatible christianity espe...         1\n",
       "2      seriously say thing first get complex explain ...        -1\n",
       "3      learned want teach different focus goal not wr...         0\n",
       "4      benefit may want read living buddha living chr...         1\n",
       "...                                                  ...       ...\n",
       "36788                                              jesus         0\n",
       "36789  kya bhai pure saal chutiya banaya modi aur jab...         1\n",
       "36790               downvote karna tha par upvote hogaya         0\n",
       "36791                                          haha nice         1\n",
       "36792                          facebook working bjp cell         0\n",
       "\n",
       "[36793 rows x 2 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\anime\\OneDrive\\Desktop\\Data Science Projects\\Youtube Comment Analysis\\youtube_comment_analyser\\data\\processed\\reddit_preprocessing.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36661, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df =  df.dropna(subset=[\"clean_comment\"])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearn\n",
      "  Using cached imblearn-0.0-py2.py3-none-any.whl.metadata (355 bytes)\n",
      "Collecting imbalanced-learn (from imblearn)\n",
      "  Downloading imbalanced_learn-0.13.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.24.3 in c:\\users\\anime\\onedrive\\desktop\\data science projects\\youtube comment analysis\\comment_analysis\\lib\\site-packages (from imbalanced-learn->imblearn) (2.2.3)\n",
      "Requirement already satisfied: scipy<2,>=1.10.1 in c:\\users\\anime\\onedrive\\desktop\\data science projects\\youtube comment analysis\\comment_analysis\\lib\\site-packages (from imbalanced-learn->imblearn) (1.15.2)\n",
      "Requirement already satisfied: scikit-learn<2,>=1.3.2 in c:\\users\\anime\\onedrive\\desktop\\data science projects\\youtube comment analysis\\comment_analysis\\lib\\site-packages (from imbalanced-learn->imblearn) (1.6.1)\n",
      "Collecting sklearn-compat<1,>=0.1 (from imbalanced-learn->imblearn)\n",
      "  Downloading sklearn_compat-0.1.3-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: joblib<2,>=1.1.1 in c:\\users\\anime\\onedrive\\desktop\\data science projects\\youtube comment analysis\\comment_analysis\\lib\\site-packages (from imbalanced-learn->imblearn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in c:\\users\\anime\\onedrive\\desktop\\data science projects\\youtube comment analysis\\comment_analysis\\lib\\site-packages (from imbalanced-learn->imblearn) (3.6.0)\n",
      "Using cached imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Downloading imbalanced_learn-0.13.0-py3-none-any.whl (238 kB)\n",
      "Downloading sklearn_compat-0.1.3-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: sklearn-compat, imbalanced-learn, imblearn\n",
      "Successfully installed imbalanced-learn-0.13.0 imblearn-0.0 sklearn-compat-0.1.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.combine import SMOTEENN\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/16 18:53:59 INFO mlflow.tracking.fluent: Experiment with name 'Handling Imbalanced Data' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='s3://datascienceanimesh/170722429091124766', creation_time=1742131439068, experiment_id='170722429091124766', last_update_time=1742131439068, lifecycle_stage='active', name='Handling Imbalanced Data', tags={}>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "mlflow.set_tracking_uri(os.getenv(\"MLFLOW_TRACKING_URI\"))\n",
    "mlflow.set_experiment(\"Handling Imbalanced Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/16 18:56:21 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Imbalance_class_weights_RandomForest_TFIDF_Bigrams at: http://ec2-13-61-189-147.eu-north-1.compute.amazonaws.com:5000/#/experiments/170722429091124766/runs/d1cb5047f2c44d989f5e72e3ffeed5ee\n",
      "üß™ View experiment at: http://ec2-13-61-189-147.eu-north-1.compute.amazonaws.com:5000/#/experiments/170722429091124766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/16 18:58:24 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Imbalance_oversampling_RandomForest_TFIDF_Bigrams at: http://ec2-13-61-189-147.eu-north-1.compute.amazonaws.com:5000/#/experiments/170722429091124766/runs/b329601a50a04fe2887940b6e666ed6e\n",
      "üß™ View experiment at: http://ec2-13-61-189-147.eu-north-1.compute.amazonaws.com:5000/#/experiments/170722429091124766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/16 19:01:30 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Imbalance_adasyn_RandomForest_TFIDF_Bigrams at: http://ec2-13-61-189-147.eu-north-1.compute.amazonaws.com:5000/#/experiments/170722429091124766/runs/4f2da910d28045409782f066220292c7\n",
      "üß™ View experiment at: http://ec2-13-61-189-147.eu-north-1.compute.amazonaws.com:5000/#/experiments/170722429091124766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/16 19:02:04 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Imbalance_undersampling_RandomForest_TFIDF_Bigrams at: http://ec2-13-61-189-147.eu-north-1.compute.amazonaws.com:5000/#/experiments/170722429091124766/runs/7bb4341b04e44b3ab92c9202f62a0e98\n",
      "üß™ View experiment at: http://ec2-13-61-189-147.eu-north-1.compute.amazonaws.com:5000/#/experiments/170722429091124766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anime\\OneDrive\\Desktop\\Data Science Projects\\Youtube Comment Analysis\\comment_analysis\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\anime\\OneDrive\\Desktop\\Data Science Projects\\Youtube Comment Analysis\\comment_analysis\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\anime\\OneDrive\\Desktop\\Data Science Projects\\Youtube Comment Analysis\\comment_analysis\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2025/03/16 19:03:05 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Imbalance_smote_enn_RandomForest_TFIDF_Bigrams at: http://ec2-13-61-189-147.eu-north-1.compute.amazonaws.com:5000/#/experiments/170722429091124766/runs/102f9a3533a24857a0a801977be82c62\n",
      "üß™ View experiment at: http://ec2-13-61-189-147.eu-north-1.compute.amazonaws.com:5000/#/experiments/170722429091124766\n"
     ]
    }
   ],
   "source": [
    "def run_imbalanced_experiment(imbalance_method):\n",
    "    ngram_range = (1, 2)  # Bigram setting\n",
    "    max_features = 1000  # Set max_features to 1000 for TF-IDF\n",
    "\n",
    "    # Step 4: Train-test split before vectorization and resampling\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df['clean_comment'], df['category'], test_size=0.2, random_state=42, stratify=df['category'])\n",
    "\n",
    "    # Step 2: Vectorization using TF-IDF, fit on training data only\n",
    "    vectorizer = TfidfVectorizer(ngram_range=ngram_range, max_features=max_features)\n",
    "    X_train_vec = vectorizer.fit_transform(X_train)  # Fit on training data\n",
    "    X_test_vec = vectorizer.transform(X_test)  # Transform test data\n",
    "\n",
    "    # Step 3: Handle class imbalance based on the selected method (only applied to the training set)\n",
    "    if imbalance_method == 'class_weights':\n",
    "        # Use class_weight in Random Forest\n",
    "        class_weight = 'balanced'\n",
    "    else:\n",
    "        class_weight = None  # Do not apply class_weight if using resampling\n",
    "\n",
    "        # Resampling Techniques (only apply to the training set)\n",
    "        if imbalance_method == 'oversampling':\n",
    "            smote = SMOTE(random_state=42)\n",
    "            X_train_vec, y_train = smote.fit_resample(X_train_vec, y_train)\n",
    "        elif imbalance_method == 'adasyn':\n",
    "            adasyn = ADASYN(random_state=42)\n",
    "            X_train_vec, y_train = adasyn.fit_resample(X_train_vec, y_train)\n",
    "        elif imbalance_method == 'undersampling':\n",
    "            rus = RandomUnderSampler(random_state=42)\n",
    "            X_train_vec, y_train = rus.fit_resample(X_train_vec, y_train)\n",
    "        elif imbalance_method == 'smote_enn':\n",
    "            smote_enn = SMOTEENN(random_state=42)\n",
    "            X_train_vec, y_train = smote_enn.fit_resample(X_train_vec, y_train)\n",
    "\n",
    "    # Step 5: Define and train a Random Forest model\n",
    "    with mlflow.start_run() as run:\n",
    "        # Set tags for the experiment and run\n",
    "        mlflow.set_tag(\"mlflow.runName\", f\"Imbalance_{imbalance_method}_RandomForest_TFIDF_Bigrams\")\n",
    "        mlflow.set_tag(\"experiment_type\", \"imbalance_handling\")\n",
    "        mlflow.set_tag(\"model_type\", \"RandomForestClassifier\")\n",
    "\n",
    "        # Add a description\n",
    "        mlflow.set_tag(\"description\", f\"RandomForest with TF-IDF Bigrams, imbalance handling method={imbalance_method}\")\n",
    "\n",
    "        # Log vectorizer parameters\n",
    "        mlflow.log_param(\"vectorizer_type\", \"TF-IDF\")\n",
    "        mlflow.log_param(\"ngram_range\", ngram_range)\n",
    "        mlflow.log_param(\"vectorizer_max_features\", max_features)\n",
    "\n",
    "        # Log Random Forest parameters\n",
    "        n_estimators = 200\n",
    "        max_depth = 15\n",
    "\n",
    "        mlflow.log_param(\"n_estimators\", n_estimators)\n",
    "        mlflow.log_param(\"max_depth\", max_depth)\n",
    "        mlflow.log_param(\"imbalance_method\", imbalance_method)\n",
    "\n",
    "        # Initialize and train the model\n",
    "        model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=42, class_weight=class_weight)\n",
    "        model.fit(X_train_vec, y_train)\n",
    "\n",
    "        # Step 6: Make predictions and log metrics\n",
    "        y_pred = model.predict(X_test_vec)\n",
    "\n",
    "        # Log accuracy\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "        # Log classification report\n",
    "        classification_rep = classification_report(y_test, y_pred, output_dict=True)\n",
    "        for label, metrics in classification_rep.items():\n",
    "            if isinstance(metrics, dict):\n",
    "                for metric, value in metrics.items():\n",
    "                    mlflow.log_metric(f\"{label}_{metric}\", value)\n",
    "\n",
    "        # Log confusion matrix\n",
    "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"Actual\")\n",
    "        plt.title(f\"Confusion Matrix: TF-IDF Trigrams, Imbalance={imbalance_method}\")\n",
    "        confusion_matrix_filename = f\"confusion_matrix_{imbalance_method}.png\"\n",
    "        plt.savefig(confusion_matrix_filename)\n",
    "        mlflow.log_artifact(confusion_matrix_filename)\n",
    "        plt.close()\n",
    "\n",
    "        # Log the model\n",
    "        mlflow.sklearn.log_model(model, f\"random_forest_model_tfidf_trigrams_imbalance_{imbalance_method}\")\n",
    "\n",
    "# Step 7: Run experiments for different imbalance methods\n",
    "imbalance_methods = ['class_weights', 'oversampling', 'adasyn', 'undersampling', 'smote_enn']\n",
    "\n",
    "for method in imbalance_methods:\n",
    "    run_imbalanced_experiment(method)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comment_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
