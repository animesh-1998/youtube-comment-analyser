{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfedb46a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_comment</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>family mormon never tried explain still stare ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>buddhism much lot compatible christianity espe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seriously say thing first get complex explain ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>learned want teach different focus goal not wr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>benefit may want read living buddha living chr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36788</th>\n",
       "      <td>jesus</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36789</th>\n",
       "      <td>kya bhai pure saal chutiya banaya modi aur jab...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36790</th>\n",
       "      <td>downvote karna tha par upvote hogaya</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36791</th>\n",
       "      <td>haha nice</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36792</th>\n",
       "      <td>facebook working bjp cell</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36793 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           clean_comment  category\n",
       "0      family mormon never tried explain still stare ...         1\n",
       "1      buddhism much lot compatible christianity espe...         1\n",
       "2      seriously say thing first get complex explain ...        -1\n",
       "3      learned want teach different focus goal not wr...         0\n",
       "4      benefit may want read living buddha living chr...         1\n",
       "...                                                  ...       ...\n",
       "36788                                              jesus         0\n",
       "36789  kya bhai pure saal chutiya banaya modi aur jab...         1\n",
       "36790               downvote karna tha par upvote hogaya         0\n",
       "36791                                          haha nice         1\n",
       "36792                          facebook working bjp cell         0\n",
       "\n",
       "[36793 rows x 2 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\anime\\OneDrive\\Desktop\\Data Science Projects\\Youtube Comment Analysis\\youtube_comment_analyser\\data\\processed\\reddit_preprocessing.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c783e64f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36661, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df =  df.dropna(subset=[\"clean_comment\"])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "03515c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim==4.3.3\n",
      "  Downloading gensim-4.3.3-cp310-cp310-win_amd64.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in c:\\users\\anime\\onedrive\\desktop\\data science projects\\youtube comment analysis\\comment_analysis\\lib\\site-packages (from gensim==4.3.3) (1.26.4)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in c:\\users\\anime\\onedrive\\desktop\\data science projects\\youtube comment analysis\\comment_analysis\\lib\\site-packages (from gensim==4.3.3) (1.13.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\anime\\onedrive\\desktop\\data science projects\\youtube comment analysis\\comment_analysis\\lib\\site-packages (from gensim==4.3.3) (7.1.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\anime\\onedrive\\desktop\\data science projects\\youtube comment analysis\\comment_analysis\\lib\\site-packages (from smart-open>=1.8.1->gensim==4.3.3) (1.17.2)\n",
      "Downloading gensim-4.3.3-cp310-cp310-win_amd64.whl (24.0 MB)\n",
      "   ---------------------------------------- 0.0/24.0 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 4.5/24.0 MB 22.4 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 11.8/24.0 MB 28.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 21.5/24.0 MB 35.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 24.0/24.0 MB 35.3 MB/s eta 0:00:00\n",
      "Installing collected packages: gensim\n",
      "Successfully installed gensim-4.3.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --no-cache-dir gensim==4.3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00ca90e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\anime\\onedrive\\desktop\\data science projects\\youtube comment analysis\\comment_analysis\\lib\\site-packages (1.26.4)\n",
      "Collecting numpy\n",
      "  Downloading numpy-2.2.4-cp310-cp310-win_amd64.whl.metadata (60 kB)\n",
      "Downloading numpy-2.2.4-cp310-cp310-win_amd64.whl (12.9 MB)\n",
      "   ---------------------------------------- 0.0/12.9 MB ? eta -:--:--\n",
      "   --------------------- ------------------ 6.8/12.9 MB 38.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.9/12.9 MB 42.7 MB/s eta 0:00:00\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "Successfully installed numpy-2.2.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.2.4 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "72ea06e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: gensim 4.3.3\n",
      "Uninstalling gensim-4.3.3:\n",
      "  Successfully uninstalled gensim-4.3.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip uninstall gensim -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a1ad719d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cythonNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading Cython-3.0.12-cp310-cp310-win_amd64.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: numpy==1.26.4 in c:\\users\\anime\\onedrive\\desktop\\data science projects\\youtube comment analysis\\comment_analysis\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\anime\\onedrive\\desktop\\data science projects\\youtube comment analysis\\comment_analysis\\lib\\site-packages (75.8.2)\n",
      "Requirement already satisfied: wheel in c:\\users\\anime\\onedrive\\desktop\\data science projects\\youtube comment analysis\\comment_analysis\\lib\\site-packages (0.45.1)\n",
      "Downloading Cython-3.0.12-cp310-cp310-win_amd64.whl (2.8 MB)\n",
      "   ---------------------------------------- 0.0/2.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.8/2.8 MB 32.3 MB/s eta 0:00:00\n",
      "Installing collected packages: cython\n",
      "Successfully installed cython-3.0.12\n"
     ]
    }
   ],
   "source": [
    "pip install cython numpy==1.26.4 setuptools wheel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6b734309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × pip subprocess to install build dependencies did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [103 lines of output]\n",
      "      Ignoring numpy: markers 'python_version == \"3.8\" and platform_machine not in \"arm64|aarch64\"' don't match your environment\n",
      "      Collecting Cython<3.0.0,>=0.29.32\n",
      "        Downloading Cython-0.29.37.tar.gz (2.1 MB)\n",
      "           ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "           ---------------------------------------- 2.1/2.1 MB 39.1 MB/s eta 0:00:00\n",
      "        Preparing metadata (setup.py): started\n",
      "        Preparing metadata (setup.py): finished with status 'done'\n",
      "      Collecting oldest-supported-numpy\n",
      "        Downloading oldest-supported-numpy-2023.12.21.tar.gz (5.2 kB)\n",
      "        Preparing metadata (setup.py): started\n",
      "        Preparing metadata (setup.py): finished with status 'done'\n",
      "      Collecting setuptools\n",
      "        Downloading setuptools-78.1.0.tar.gz (1.4 MB)\n",
      "           ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "           ---------------------------------------- 1.4/1.4 MB 35.7 MB/s eta 0:00:00\n",
      "        Getting requirements to build wheel: started\n",
      "        Getting requirements to build wheel: finished with status 'done'\n",
      "        Preparing metadata (pyproject.toml): started\n",
      "        Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "      Collecting wheel\n",
      "        Downloading wheel-0.45.1.tar.gz (107 kB)\n",
      "        Installing build dependencies: started\n",
      "        Installing build dependencies: finished with status 'done'\n",
      "        Getting requirements to build wheel: started\n",
      "        Getting requirements to build wheel: finished with status 'done'\n",
      "        Preparing metadata (pyproject.toml): started\n",
      "        Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "      Collecting numpy==1.21.6 (from oldest-supported-numpy)\n",
      "        Downloading numpy-1.21.6.zip (10.3 MB)\n",
      "           ---------------------------------------- 0.0/10.3 MB ? eta -:--:--\n",
      "           --------------------------------- ------ 8.7/10.3 MB 48.8 MB/s eta 0:00:01\n",
      "           --------------------------------------- 10.3/10.3 MB 42.8 MB/s eta 0:00:00\n",
      "        Installing build dependencies: started\n",
      "        Installing build dependencies: finished with status 'error'\n",
      "        error: subprocess-exited-with-error\n",
      "      \n",
      "        Ã— pip subprocess to install build dependencies did not run successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim==4.3.3\n",
      "  Downloading gensim-4.3.3.tar.gz (23.3 MB)\n",
      "     ---------------------------------------- 0.0/23.3 MB ? eta -:--:--\n",
      "     ------- -------------------------------- 4.5/23.3 MB 24.4 MB/s eta 0:00:01\n",
      "     ------------------------ -------------- 14.4/23.3 MB 36.2 MB/s eta 0:00:01\n",
      "     --------------------------------------  23.1/23.3 MB 39.5 MB/s eta 0:00:01\n",
      "     --------------------------------------- 23.3/23.3 MB 35.1 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        â”‚ exit code: 1\n",
      "        â•°â”€> [54 lines of output]\n",
      "            Ignoring packaging: markers 'platform_machine == \"arm64\"' don't match your environment\n",
      "            Collecting setuptools==59.2.0\n",
      "              Downloading setuptools-59.2.0.tar.gz (2.3 MB)\n",
      "                 ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
      "                 ---------------------------------------- 2.3/2.3 MB 43.9 MB/s eta 0:00:00\n",
      "              Getting requirements to build wheel: started\n",
      "              Getting requirements to build wheel: finished with status 'error'\n",
      "              error: subprocess-exited-with-error\n",
      "      \n",
      "              Ãƒâ€” Getting requirements to build wheel did not run successfully.\n",
      "              Ã¢â€\\x9dâ€š exit code: 1\n",
      "              Ã¢â€¢Â°Ã¢â€\\x9dâ‚¬> [32 lines of output]\n",
      "                  Traceback (most recent call last):\n",
      "                    File \"C:\\Users\\anime\\OneDrive\\Desktop\\Data Science Projects\\Youtube Comment Analysis\\comment_analysis\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 389, in <module>\n",
      "                      main()\n",
      "                    File \"C:\\Users\\anime\\OneDrive\\Desktop\\Data Science Projects\\Youtube Comment Analysis\\comment_analysis\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 373, in main\n",
      "                      json_out[\"return_val\"] = hook(**hook_input[\"kwargs\"])\n",
      "                    File \"C:\\Users\\anime\\OneDrive\\Desktop\\Data Science Projects\\Youtube Comment Analysis\\comment_analysis\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 143, in get_requires_for_build_wheel\n",
      "                      return hook(config_settings)\n",
      "                    File \"C:\\Users\\anime\\AppData\\Local\\Temp\\pip-install-7ccs11gy\\setuptools_1eac40aba2674e43b870ca55c5f055f8\\setuptools\\build_meta.py\", line 162, in get_requires_for_build_wheel\n",
      "                      return self._get_build_requires(\n",
      "                    File \"C:\\Users\\anime\\AppData\\Local\\Temp\\pip-install-7ccs11gy\\setuptools_1eac40aba2674e43b870ca55c5f055f8\\setuptools\\build_meta.py\", line 143, in _get_build_requires\n",
      "                      self.run_setup()\n",
      "                    File \"C:\\Users\\anime\\AppData\\Local\\Temp\\pip-install-7ccs11gy\\setuptools_1eac40aba2674e43b870ca55c5f055f8\\setuptools\\build_meta.py\", line 158, in run_setup\n",
      "                      exec(compile(code, __file__, 'exec'), locals())\n",
      "                    File \"setup.py\", line 87, in <module>\n",
      "                      dist = setuptools.setup(**setup_params)\n",
      "                    File \"C:\\Users\\anime\\AppData\\Local\\Temp\\pip-install-7ccs11gy\\setuptools_1eac40aba2674e43b870ca55c5f055f8\\setuptools\\__init__.py\", line 152, in setup\n",
      "                      _install_setup_requires(attrs)\n",
      "                    File \"C:\\Users\\anime\\AppData\\Local\\Temp\\pip-install-7ccs11gy\\setuptools_1eac40aba2674e43b870ca55c5f055f8\\setuptools\\__init__.py\", line 145, in _install_setup_requires\n",
      "                      dist.parse_config_files(ignore_option_errors=True)\n",
      "                    File \"c:\\Users\\anime\\OneDrive\\Desktop\\Data Science Projects\\Youtube Comment Analysis\\comment_analysis\\lib\\site-packages\\_virtualenv.py\", line 22, in parse_config_files\n",
      "                      result = old_parse_config_files(self, *args, **kwargs)\n",
      "                    File \"C:\\Users\\anime\\AppData\\Local\\Temp\\pip-install-7ccs11gy\\setuptools_1eac40aba2674e43b870ca55c5f055f8\\setuptools\\dist.py\", line 798, in parse_config_files\n",
      "                      parse_configuration(\n",
      "                    File \"C:\\Users\\anime\\AppData\\Local\\Temp\\pip-install-7ccs11gy\\setuptools_1eac40aba2674e43b870ca55c5f055f8\\setuptools\\config.py\", line 150, in parse_configuration\n",
      "                      options.parse()\n",
      "                    File \"C:\\Users\\anime\\AppData\\Local\\Temp\\pip-install-7ccs11gy\\setuptools_1eac40aba2674e43b870ca55c5f055f8\\setuptools\\config.py\", line 498, in parse\n",
      "                      section_parser_method(section_options)\n",
      "                    File \"C:\\Users\\anime\\AppData\\Local\\Temp\\pip-install-7ccs11gy\\setuptools_1eac40aba2674e43b870ca55c5f055f8\\setuptools\\config.py\", line 709, in parse_section_entry_points\n",
      "                      self['entry_points'] = parsed\n",
      "                    File \"C:\\Users\\anime\\AppData\\Local\\Temp\\pip-install-7ccs11gy\\setuptools_1eac40aba2674e43b870ca55c5f055f8\\setuptools\\config.py\", line 212, in __setitem__\n",
      "                      raise KeyError(option_name)\n",
      "                  KeyError: 'entry_points'\n",
      "                  [end of output]\n",
      "      \n",
      "              note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "            error: subprocess-exited-with-error\n",
      "      \n",
      "            Ãƒâ€” Getting requirements to build wheel did not run successfully.\n",
      "            Ã¢â€\\x9dâ€š exit code: 1\n",
      "            Ã¢â€¢Â°Ã¢â€\\x9dâ‚¬> See above for output.\n",
      "      \n",
      "            note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "            [end of output]\n",
      "      \n",
      "        note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "      error: subprocess-exited-with-error\n",
      "      \n",
      "      Ã— pip subprocess to install build dependencies did not run successfully.\n",
      "      â”‚ exit code: 1\n",
      "      â•°â”€> See above for output.\n",
      "      \n",
      "      note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "× pip subprocess to install build dependencies did not run successfully.\n",
      "│ exit code: 1\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    }
   ],
   "source": [
    "pip install --no-binary :all: gensim==4.3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e4466724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy<2.0\n",
      "  Using cached numpy-1.26.4-cp310-cp310-win_amd64.whl.metadata (61 kB)\n",
      "Using cached numpy-1.26.4-cp310-cp310-win_amd64.whl (15.8 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "Successfully installed numpy-1.26.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install \"numpy<2.0\" --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0decdf5d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StratifiedKFold\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Word2Vec\n",
      "File \u001b[1;32mc:\\Users\\anime\\OneDrive\\Desktop\\Data Science Projects\\Youtube Comment Analysis\\comment_analysis\\lib\\site-packages\\gensim\\__init__.py:11\u001b[0m\n\u001b[0;32m      7\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m4.3.3\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m parsing, corpora, matutils, interfaces, models, similarities, utils  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[0;32m     14\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgensim\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m logger\u001b[38;5;241m.\u001b[39mhandlers:  \u001b[38;5;66;03m# To ensure reload() doesn't add another one\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\anime\\OneDrive\\Desktop\\Data Science Projects\\Youtube Comment Analysis\\comment_analysis\\lib\\site-packages\\gensim\\corpora\\__init__.py:6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mThis package contains implementations of various streaming corpus I/O format.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# bring corpus classes directly into package namespace, to save some typing\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindexedcorpus\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m IndexedCorpus  \u001b[38;5;66;03m# noqa:F401 must appear before the other classes\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmmcorpus\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MmCorpus  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbleicorpus\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BleiCorpus  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\anime\\OneDrive\\Desktop\\Data Science Projects\\Youtube Comment Analysis\\comment_analysis\\lib\\site-packages\\gensim\\corpora\\indexedcorpus.py:14\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m interfaces, utils\n\u001b[0;32m     16\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mIndexedCorpus\u001b[39;00m(interfaces\u001b[38;5;241m.\u001b[39mCorpusABC):\n",
      "File \u001b[1;32mc:\\Users\\anime\\OneDrive\\Desktop\\Data Science Projects\\Youtube Comment Analysis\\comment_analysis\\lib\\site-packages\\gensim\\interfaces.py:19\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03m\"\"\"Basic interfaces used across the whole Gensim package.\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \n\u001b[0;32m      9\u001b[0m \u001b[38;5;124;03mThese interfaces are used for building corpora, model transformation and similarity queries.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m \n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m utils, matutils\n\u001b[0;32m     22\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mCorpusABC\u001b[39;00m(utils\u001b[38;5;241m.\u001b[39mSaveLoad):\n",
      "File \u001b[1;32mc:\\Users\\anime\\OneDrive\\Desktop\\Data Science Projects\\Youtube Comment Analysis\\comment_analysis\\lib\\site-packages\\gensim\\matutils.py:1034\u001b[0m\n\u001b[0;32m   1029\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m1.\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28mlen\u001b[39m(set1 \u001b[38;5;241m&\u001b[39m set2)) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mfloat\u001b[39m(union_cardinality)\n\u001b[0;32m   1032\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1033\u001b[0m     \u001b[38;5;66;03m# try to load fast, cythonized code if possible\u001b[39;00m\n\u001b[1;32m-> 1034\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_matutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m logsumexp, mean_absolute_difference, dirichlet_expectation\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m   1037\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mlogsumexp\u001b[39m(x):\n",
      "File \u001b[1;32mc:\\Users\\anime\\OneDrive\\Desktop\\Data Science Projects\\Youtube Comment Analysis\\comment_analysis\\lib\\site-packages\\gensim\\_matutils.pyx:1\u001b[0m, in \u001b[0;36minit gensim._matutils\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import optuna\n",
    "from lightgbm import LGBMClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d3ca94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/06 14:00:13 INFO mlflow.tracking.fluent: Experiment with name 'LightGBM detailed HP tuning word2vec' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='s3://datascienceanimesh/637454529299775382', creation_time=1743928213647, experiment_id='637454529299775382', last_update_time=1743928213647, lifecycle_stage='active', name='LightGBM detailed HP tuning word2vec', tags={}>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(os.getenv(\"MLFLOW_TRACKING_URI\"))\n",
    "mlflow.set_experiment(\"LightGBM detailed HP tuning word2vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ee0d21f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anime\\AppData\\Local\\Temp\\ipykernel_8580\\3371971501.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['category'] = df['category'].map({-1: 2, 0: 0, 1: 1})\n"
     ]
    }
   ],
   "source": [
    "df['category'] = df['category'].map({-1: 2, 0: 0, 1: 1})\n",
    "df = df.dropna(subset=['category'])\n",
    "\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
    "    df['clean_comment'], df['category'], test_size=0.2, random_state=42, stratify=df['category']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4bd4b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tokenized = [sentence.split() for sentence in X_train_raw]\n",
    "X_test_tokenized = [sentence.split() for sentence in X_test_raw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd1614c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "word2vec_model = Word2Vec(sentences=X_train_tokenized, vector_size=300, window=5, min_count=1, workers=4, sg=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comment_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
